{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/KM-Adnan-Absar/Sentiment_Analysis/blob/main/soham/Deep_Learning_Model/Sentiment_Analysis_WIth_LSTM.ipynb","timestamp":1771230401557}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":533},"id":"WrpbcCsWs7lc","outputId":"4fa2ccb1-e640-42ec-dc1c-5e55b0b46d22","executionInfo":{"status":"ok","timestamp":1771232595652,"user_tz":-360,"elapsed":1031,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        post_id            timestamp day_of_week   platform        user_id  \\\n","0  kcqbs6hxybia  2024-12-09 11:26:15      Monday  Instagram  user_52nwb0a6   \n","1  vkmervg4ioos  2024-07-28 19:59:26      Sunday    Twitter  user_ucryct98   \n","2  memhx4o1x6yu  2024-11-23 14:00:12    Saturday     Reddit  user_7rrev126   \n","3  bhyo6piijqt9   2024-09-16 4:35:25      Monday    YouTube  user_4mxuq0ax   \n","4  c9dkiomowakt  2024-09-05 21:03:01    Thursday    Twitter  user_l1vpox2k   \n","\n","               location language  \\\n","0  Melbourne, Australia       pt   \n","1          Tokyo, Japan       ru   \n","2        Beijing, China       ru   \n","3        Lagos, Nigeria       en   \n","4       Berlin, Germany       hi   \n","\n","                                        text_content  \\\n","0  Just tried the Chromebook from Google. Best pu...   \n","1  Just saw an ad for Microsoft Surface Laptop du...   \n","2  What's your opinion about Nike's Epic React?  ...   \n","3  Bummed out with my new Diet Pepsi from Pepsi! ...   \n","4  Just tried the Corolla from Toyota. Absolutely...   \n","\n","                             translated_text_content  \\\n","0  গুগল থেকে Chromebook ব্যবহার করে দেখুন। সর্বকা...   \n","1  স্প্রিংব্লাস্ট ২০২৫-এর সময় মাইক্রোসফট সারফেস ...   \n","2  নাইকির এপিক রিঅ্যাক্ট সম্পর্কে আপনার মতামত কী?...   \n","3  পেপসির নতুন ডায়েট পেপসি দেখে হতাশ! মান নিয়ে ...   \n","4  টয়োটার করোলাটা ট্রাই করলাম। সত্যিই খুব ভালো ল...   \n","\n","                   hashtags  ... comments_count impressions engagement_rate  \\\n","0                     #Food  ...            701       18991         0.19319   \n","1          #MustHave, #Food  ...            359       52764         0.05086   \n","2  #Promo, #Food, #Trending  ...            643        8887         0.45425   \n","3    #Reviews, #Sustainable  ...            743        6696         0.42293   \n","4          #Health, #Travel  ...            703       47315         0.08773   \n","\n","   brand_name    product_name     campaign_name  campaign_phase  \\\n","0      Google      Chromebook       BlackFriday          Launch   \n","1   Microsoft  Surface Laptop      PowerRelease     Post-Launch   \n","2        Nike      Epic React       BlackFriday     Post-Launch   \n","3       Pepsi      Diet Pepsi        LaunchWave          Launch   \n","4      Toyota         Corolla  LocalTouchpoints          Launch   \n","\n","   user_past_sentiment_avg  user_engagement_growth  buzz_change_rate  \n","0                   0.0953                 -0.3672              19.1  \n","1                   0.1369                 -0.4510             -42.6  \n","2                   0.2855                 -0.4112              17.4  \n","3                  -0.2094                 -0.0167              -5.5  \n","4                   0.6867                  0.0807              38.8  \n","\n","[5 rows x 29 columns]"],"text/html":["\n","  <div id=\"df-5aac7726-1baf-4cfd-ab38-0b2228bf66f1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>post_id</th>\n","      <th>timestamp</th>\n","      <th>day_of_week</th>\n","      <th>platform</th>\n","      <th>user_id</th>\n","      <th>location</th>\n","      <th>language</th>\n","      <th>text_content</th>\n","      <th>translated_text_content</th>\n","      <th>hashtags</th>\n","      <th>...</th>\n","      <th>comments_count</th>\n","      <th>impressions</th>\n","      <th>engagement_rate</th>\n","      <th>brand_name</th>\n","      <th>product_name</th>\n","      <th>campaign_name</th>\n","      <th>campaign_phase</th>\n","      <th>user_past_sentiment_avg</th>\n","      <th>user_engagement_growth</th>\n","      <th>buzz_change_rate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>kcqbs6hxybia</td>\n","      <td>2024-12-09 11:26:15</td>\n","      <td>Monday</td>\n","      <td>Instagram</td>\n","      <td>user_52nwb0a6</td>\n","      <td>Melbourne, Australia</td>\n","      <td>pt</td>\n","      <td>Just tried the Chromebook from Google. Best pu...</td>\n","      <td>গুগল থেকে Chromebook ব্যবহার করে দেখুন। সর্বকা...</td>\n","      <td>#Food</td>\n","      <td>...</td>\n","      <td>701</td>\n","      <td>18991</td>\n","      <td>0.19319</td>\n","      <td>Google</td>\n","      <td>Chromebook</td>\n","      <td>BlackFriday</td>\n","      <td>Launch</td>\n","      <td>0.0953</td>\n","      <td>-0.3672</td>\n","      <td>19.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vkmervg4ioos</td>\n","      <td>2024-07-28 19:59:26</td>\n","      <td>Sunday</td>\n","      <td>Twitter</td>\n","      <td>user_ucryct98</td>\n","      <td>Tokyo, Japan</td>\n","      <td>ru</td>\n","      <td>Just saw an ad for Microsoft Surface Laptop du...</td>\n","      <td>স্প্রিংব্লাস্ট ২০২৫-এর সময় মাইক্রোসফট সারফেস ...</td>\n","      <td>#MustHave, #Food</td>\n","      <td>...</td>\n","      <td>359</td>\n","      <td>52764</td>\n","      <td>0.05086</td>\n","      <td>Microsoft</td>\n","      <td>Surface Laptop</td>\n","      <td>PowerRelease</td>\n","      <td>Post-Launch</td>\n","      <td>0.1369</td>\n","      <td>-0.4510</td>\n","      <td>-42.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>memhx4o1x6yu</td>\n","      <td>2024-11-23 14:00:12</td>\n","      <td>Saturday</td>\n","      <td>Reddit</td>\n","      <td>user_7rrev126</td>\n","      <td>Beijing, China</td>\n","      <td>ru</td>\n","      <td>What's your opinion about Nike's Epic React?  ...</td>\n","      <td>নাইকির এপিক রিঅ্যাক্ট সম্পর্কে আপনার মতামত কী?...</td>\n","      <td>#Promo, #Food, #Trending</td>\n","      <td>...</td>\n","      <td>643</td>\n","      <td>8887</td>\n","      <td>0.45425</td>\n","      <td>Nike</td>\n","      <td>Epic React</td>\n","      <td>BlackFriday</td>\n","      <td>Post-Launch</td>\n","      <td>0.2855</td>\n","      <td>-0.4112</td>\n","      <td>17.4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bhyo6piijqt9</td>\n","      <td>2024-09-16 4:35:25</td>\n","      <td>Monday</td>\n","      <td>YouTube</td>\n","      <td>user_4mxuq0ax</td>\n","      <td>Lagos, Nigeria</td>\n","      <td>en</td>\n","      <td>Bummed out with my new Diet Pepsi from Pepsi! ...</td>\n","      <td>পেপসির নতুন ডায়েট পেপসি দেখে হতাশ! মান নিয়ে ...</td>\n","      <td>#Reviews, #Sustainable</td>\n","      <td>...</td>\n","      <td>743</td>\n","      <td>6696</td>\n","      <td>0.42293</td>\n","      <td>Pepsi</td>\n","      <td>Diet Pepsi</td>\n","      <td>LaunchWave</td>\n","      <td>Launch</td>\n","      <td>-0.2094</td>\n","      <td>-0.0167</td>\n","      <td>-5.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>c9dkiomowakt</td>\n","      <td>2024-09-05 21:03:01</td>\n","      <td>Thursday</td>\n","      <td>Twitter</td>\n","      <td>user_l1vpox2k</td>\n","      <td>Berlin, Germany</td>\n","      <td>hi</td>\n","      <td>Just tried the Corolla from Toyota. Absolutely...</td>\n","      <td>টয়োটার করোলাটা ট্রাই করলাম। সত্যিই খুব ভালো ল...</td>\n","      <td>#Health, #Travel</td>\n","      <td>...</td>\n","      <td>703</td>\n","      <td>47315</td>\n","      <td>0.08773</td>\n","      <td>Toyota</td>\n","      <td>Corolla</td>\n","      <td>LocalTouchpoints</td>\n","      <td>Launch</td>\n","      <td>0.6867</td>\n","      <td>0.0807</td>\n","      <td>38.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 29 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aac7726-1baf-4cfd-ab38-0b2228bf66f1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5aac7726-1baf-4cfd-ab38-0b2228bf66f1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5aac7726-1baf-4cfd-ab38-0b2228bf66f1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":1}],"source":["import numpy as np\n","import pandas as pd\n","\n","data = pd.read_csv('/content/train_ctrUa4K.csv')\n","data.head()"]},{"cell_type":"code","source":["reviews = data['translated_text_content'].values[:12000]\n","labels  = data['sentiment_label'].values[:12000]\n","\n","\n"],"metadata":{"id":"CjroTz4PtYBq","executionInfo":{"status":"ok","timestamp":1771232602058,"user_tz":-360,"elapsed":21,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data['translated_text_content'].loc[1039]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"SWgB9pjcvj7w","outputId":"5a85fa32-0706-4261-fdcf-e93a582181c8","executionInfo":{"status":"ok","timestamp":1771232604960,"user_tz":-360,"elapsed":36,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'প্রতিযোগীর সাথে Microsoft Surface Duo এর তুলনা করা হচ্ছে। সুপারিশ করব না। #ফ্যাশন, #টেকসই আপনার প্রতিক্রিয়া জানতে আগ্রহী!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["data['sentiment_label'].loc[1039]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"1Y4P3_YLv0Vd","outputId":"2d746e73-a53f-43b5-a3e0-fb988b4ef336","executionInfo":{"status":"ok","timestamp":1771232607870,"user_tz":-360,"elapsed":12,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Negative'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from collections import Counter\n","\n","Counter(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdZPG6q5wBq9","outputId":"8c54b6d1-7e1e-4c49-e651-32818b5bee8e","executionInfo":{"status":"ok","timestamp":1771232609331,"user_tz":-360,"elapsed":18,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'Positive': 4839, 'Negative': 4854, 'Neutral': 2307})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["\n","punctuation = '!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~'\n","\n","# get rid of punctuation\n","all_reviews = 'separator'.join(reviews)\n","all_reviews = all_reviews.lower()\n","all_text = ''.join([c for c in all_reviews if c not in punctuation])\n","\n","# split by new lines and spaces\n","reviews_split = all_text.split('separator')\n","all_text = ' '.join(reviews_split)\n","\n","# create a list of words\n","words = all_text.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QPtSlYESwHNN","outputId":"ea9f616a-d77f-47e4-d81f-0d94e1ca70a3","executionInfo":{"status":"ok","timestamp":1771232611758,"user_tz":-360,"elapsed":242,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<>:1: SyntaxWarning: invalid escape sequence '\\]'\n","<>:1: SyntaxWarning: invalid escape sequence '\\]'\n","/tmp/ipython-input-2748096650.py:1: SyntaxWarning: invalid escape sequence '\\]'\n","  punctuation = '!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~'\n"]}]},{"cell_type":"code","source":["# get rid of web address, twitter id, and digit\n","new_reviews = []\n","for review in reviews_split:\n","    review = review.split()\n","    new_text = []\n","    for word in review:\n","        if (word[0] != '@') & ('http' not in word) & (~word.isdigit()):\n","            new_text.append(word)\n","    new_reviews.append(new_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PrZPQMQwPUe","outputId":"f135b280-f56c-4c3e-af10-98f7147a427e","executionInfo":{"status":"ok","timestamp":1771232617170,"user_tz":-360,"elapsed":181,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2777777309.py:7: DeprecationWarning: Bitwise inversion '~' on bool is deprecated and will be removed in Python 3.16. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n","  if (word[0] != '@') & ('http' not in word) & (~word.isdigit()):\n"]}]},{"cell_type":"code","source":["\n","## Build a dictionary that maps words to integers\n","counts = Counter(words)\n","vocab = sorted(counts, key=counts.get, reverse=True)\n","vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n","\n","## use the dict to tokenize each review in reviews_split\n","## store the tokenized reviews in reviews_ints\n","reviews_ints = []\n","for review in new_reviews:\n","    reviews_ints.append([vocab_to_int[word] for word in review])"],"metadata":{"id":"25Wo2weCwTm2","executionInfo":{"status":"ok","timestamp":1771232621682,"user_tz":-360,"elapsed":35,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","# stats about vocabulary\n","print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n","print()\n","\n","# print tokens in first review\n","print('Tokenized review: \\n', reviews_ints[:1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F44u-MuewX6y","outputId":"1bb18e48-29f2-4585-b2a8-41d5689a6f8b","executionInfo":{"status":"ok","timestamp":1771232624778,"user_tz":-360,"elapsed":47,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique words:  1176\n","\n","Tokenized review: \n"," [[57, 19, 519, 48, 25, 726, 78, 55, 109, 103, 1, 2, 9, 6, 5]]\n"]}]},{"cell_type":"code","source":["\n","# 2=positive, 1=neutral, 0=negative label conversion\n","encoded_labels = []\n","for label in labels:\n","    label = label.lower()   # normalize case\n","    if label == 'neutral':\n","        encoded_labels.append(1)\n","    elif label == 'negative':\n","        encoded_labels.append(0)\n","    elif label == 'positive':\n","        encoded_labels.append(2)\n","    else:\n","        raise ValueError(f\"Unknown label: {label}\")\n","\n","encoded_labels = np.asarray(encoded_labels)\n","\n"],"metadata":{"id":"DsZ-eas0w6va","executionInfo":{"status":"ok","timestamp":1771232627874,"user_tz":-360,"elapsed":19,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","encoded_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nKdsAU2xsLf","outputId":"e3ce098b-7358-4d92-8298-3a63462432d9","executionInfo":{"status":"ok","timestamp":1771232630939,"user_tz":-360,"elapsed":11,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 0, 0, ..., 2, 1, 0])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["\n","def pad_features(reviews_ints, seq_length):\n","    ''' Return features of review_ints, where each review is padded with 0's\n","        or truncated to the input seq_length.\n","    '''\n","\n","    # getting the correct rows x cols shape\n","    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n","\n","    # for each review, I grab that review and\n","    for i, row in enumerate(reviews_ints):\n","        features[i, -len(row):] = np.array(row)[:seq_length]\n","\n","    return features\n"],"metadata":{"id":"sfeM18u7x06_","executionInfo":{"status":"ok","timestamp":1771232632735,"user_tz":-360,"elapsed":8,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["seq_length = 70\n","\n","features = pad_features(reviews_ints, seq_length=seq_length)\n","\n","## test statements\n","assert len(features)==len(reviews_ints), \"The features should have as many rows as reviews.\"\n","assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n","\n","# print first 10 values of the first 30 batches\n","print(features[:10,:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRPtG2ITyCtX","outputId":"c67fac78-6ec4-4c33-aa1e-d3db450598c8","executionInfo":{"status":"ok","timestamp":1771232635871,"user_tz":-360,"elapsed":28,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0]]\n"]}]},{"cell_type":"code","source":["split_frac = 0.8\n","\n","## split data into training, validation, and test data (features and labels, x and y)\n","\n","split_idx = int(len(features)*split_frac)\n","train_x, remaining_x = features[:split_idx], features[split_idx:]\n","train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n","\n","test_idx = int(len(remaining_x)*0.5)\n","val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n","val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n","\n","## print out the shapes of the resultant feature data\n","print(\"\\t\\t\\tFeature Shapes:\")\n","print(\"Train set: \\t\\t{}\".format(train_x.shape),\n","      \"\\nValidation set: \\t{}\".format(val_x.shape),\n","      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-iwpnxFy39l","outputId":"ac72177a-0b34-41c2-a372-c581f35d82f5","executionInfo":{"status":"ok","timestamp":1771232638625,"user_tz":-360,"elapsed":21,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\t\t\tFeature Shapes:\n","Train set: \t\t(9600, 70) \n","Validation set: \t(1200, 70) \n","Test set: \t\t(1200, 70)\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n","valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n","test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n","\n","# dataloaders\n","batch_size = 50\n","\n","# make sure the SHUFFLE the training data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"GfpNK73Czgcp","executionInfo":{"status":"ok","timestamp":1771232642459,"user_tz":-360,"elapsed":1683,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# obtain one batch of training data\n","\n","dataiter = iter(train_loader)\n","\n","# Correct way to get next batch:\n","sample_x, sample_y = next(dataiter)\n","\n","print('Sample input size: ', sample_x.size())   # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print()\n","print('Sample label size: ', sample_y.size())   # batch_size\n","print('Sample label: \\n', sample_y)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IfkgvqGzmVZ","outputId":"3bafe9b0-5455-4896-cdae-f6d96fe1eb07","executionInfo":{"status":"ok","timestamp":1771232647206,"user_tz":-360,"elapsed":11,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample input size:  torch.Size([50, 70])\n","Sample input: \n"," tensor([[  0,   0,   0,  ...,  10,   3,  11],\n","        [  0,   0,   0,  ...,  77, 471, 535],\n","        [  0,   0,   0,  ...,   9,   6,   5],\n","        ...,\n","        [  0,   0,   0,  ...,   2,  15,  22],\n","        [  0,   0,   0,  ...,  10,   3,  11],\n","        [  0,   0,   0,  ..., 103,  81,  77]])\n","\n","Sample label size:  torch.Size([50])\n","Sample label: \n"," tensor([0, 2, 1, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 2,\n","        2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 1, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2,\n","        1, 0])\n"]}]},{"cell_type":"code","source":["# First checking if GPU is available\n","train_on_gpu=torch.cuda.is_available()\n","\n","if(train_on_gpu):\n","    print('Training on GPU.')\n","else:\n","    print('No GPU available, training on CPU.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZ1GJskB0IJS","outputId":"90555ad3-f379-4a11-e8b7-7712ce0803f1","executionInfo":{"status":"ok","timestamp":1771232653348,"user_tz":-360,"elapsed":46,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on GPU.\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class SentimentRNN(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n","        super(SentimentRNN, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # LSTM layer\n","        self.lstm = nn.LSTM(\n","            embedding_dim,\n","            hidden_dim,\n","            n_layers,\n","            batch_first=True,\n","            dropout=drop_prob\n","        )\n","\n","        # Dropout\n","        self.dropout = nn.Dropout(0.3)\n","\n","        # IMPORTANT: 3 output neurons\n","        self.fc = nn.Linear(hidden_dim, 3)\n","\n","    def forward(self, x, hidden):\n","\n","        batch_size = x.size(0)\n","\n","        embeds = self.embedding(x)\n","\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","\n","        # Take last timestep\n","        out = lstm_out[:, -1, :]\n","\n","        out = self.dropout(out)\n","\n","        out = self.fc(out)\n","\n","        # NO sigmoid / softmax here\n","        return out, hidden\n","\n","    def init_hidden(self, batch_size):\n","\n","        device = next(self.parameters()).device\n","\n","        hidden = (\n","            torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device),\n","            torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n","        )\n","\n","        return hidden\n"],"metadata":{"id":"aDTN1dDD0QCk","executionInfo":{"status":"ok","timestamp":1771232656348,"user_tz":-360,"elapsed":14,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(vocab_to_int) + 1\n","embedding_dim = 400\n","hidden_dim = 256\n","n_layers = 2\n","\n","net = SentimentRNN(vocab_size, embedding_dim, hidden_dim, n_layers)\n","\n"],"metadata":{"id":"DNYH2LxS0VoP","executionInfo":{"status":"ok","timestamp":1771232663317,"user_tz":-360,"elapsed":21,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# loss and optimization functions\n","lr=0.001\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)"],"metadata":{"id":"VpQVqNd51_qW","executionInfo":{"status":"ok","timestamp":1771232671516,"user_tz":-360,"elapsed":1260,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["all_labels = []\n","\n","for _, lbl in train_loader:\n","    all_labels.append(lbl)\n","\n","all_labels = torch.cat(all_labels)\n","\n","print(\"Unique labels:\", torch.unique(all_labels))\n","print(\"Min label:\", all_labels.min().item())\n","print(\"Max label:\", all_labels.max().item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3D9vtCSHp-Tb","executionInfo":{"status":"ok","timestamp":1771232685301,"user_tz":-360,"elapsed":93,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}},"outputId":"5b14e5fb-7b01-430a-caee-379dab5e135d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique labels: tensor([0, 1, 2])\n","Min label: 0\n","Max label: 2\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","epochs = 20\n","counter = 0\n","print_every = 100\n","clip = 5\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n","\n","net.train()\n","\n","for e in range(epochs):\n","    for inputs, labels in train_loader:\n","\n","        counter += 1\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()   # NO subtracting now\n","\n","        h = net.init_hidden(inputs.size(0))\n","        h = tuple(each.detach() for each in h)\n","\n","        optimizer.zero_grad()\n","\n","        output, h = net(inputs, h)\n","\n","        loss = criterion(output, labels)\n","\n","        loss.backward()\n","\n","        nn.utils.clip_grad_norm_(net.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        # Validation\n","        if counter % print_every == 0:\n","            val_losses = []\n","            net.eval()\n","\n","            with torch.no_grad():\n","                for val_inputs, val_labels in valid_loader:\n","\n","                    val_inputs = val_inputs.to(device)\n","                    val_labels = val_labels.to(device).long()\n","\n","                    val_h = net.init_hidden(val_inputs.size(0))\n","                    val_h = tuple(each.detach() for each in val_h)\n","\n","                    val_output, val_h = net(val_inputs, val_h)\n","\n","                    val_loss = criterion(val_output, val_labels)\n","                    val_losses.append(val_loss.item())\n","\n","            net.train()\n","\n","            print(f\"Epoch: {e+1}/{epochs} | \"\n","                  f\"Step: {counter} | \"\n","                  f\"Train Loss: {loss.item():.6f} | \"\n","                  f\"Val Loss: {np.mean(val_losses):.6f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9x30OuS5LKJ","outputId":"5bbd9e1b-6aa4-4118-8c2e-5d98e18a9e3e","executionInfo":{"status":"ok","timestamp":1771232796767,"user_tz":-360,"elapsed":106268,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1/20 | Step: 100 | Train Loss: 0.146012 | Val Loss: 0.187677\n","Epoch: 2/20 | Step: 200 | Train Loss: 0.079170 | Val Loss: 0.149702\n","Epoch: 2/20 | Step: 300 | Train Loss: 0.173798 | Val Loss: 0.142472\n","Epoch: 3/20 | Step: 400 | Train Loss: 0.046849 | Val Loss: 0.110544\n","Epoch: 3/20 | Step: 500 | Train Loss: 0.046400 | Val Loss: 0.108755\n","Epoch: 4/20 | Step: 600 | Train Loss: 0.055365 | Val Loss: 0.119864\n","Epoch: 4/20 | Step: 700 | Train Loss: 0.129053 | Val Loss: 0.112479\n","Epoch: 5/20 | Step: 800 | Train Loss: 0.250994 | Val Loss: 0.115580\n","Epoch: 5/20 | Step: 900 | Train Loss: 0.053908 | Val Loss: 0.107003\n","Epoch: 6/20 | Step: 1000 | Train Loss: 0.093342 | Val Loss: 0.107335\n","Epoch: 6/20 | Step: 1100 | Train Loss: 0.096287 | Val Loss: 0.107873\n","Epoch: 7/20 | Step: 1200 | Train Loss: 0.014825 | Val Loss: 0.112655\n","Epoch: 7/20 | Step: 1300 | Train Loss: 0.129795 | Val Loss: 0.114244\n","Epoch: 8/20 | Step: 1400 | Train Loss: 0.034706 | Val Loss: 0.121139\n","Epoch: 8/20 | Step: 1500 | Train Loss: 0.072604 | Val Loss: 0.108929\n","Epoch: 9/20 | Step: 1600 | Train Loss: 0.062416 | Val Loss: 0.135041\n","Epoch: 9/20 | Step: 1700 | Train Loss: 0.080346 | Val Loss: 0.112577\n","Epoch: 10/20 | Step: 1800 | Train Loss: 0.034162 | Val Loss: 0.117728\n","Epoch: 10/20 | Step: 1900 | Train Loss: 0.173244 | Val Loss: 0.125246\n","Epoch: 11/20 | Step: 2000 | Train Loss: 0.116044 | Val Loss: 0.111884\n","Epoch: 11/20 | Step: 2100 | Train Loss: 0.052853 | Val Loss: 0.115626\n","Epoch: 12/20 | Step: 2200 | Train Loss: 0.040520 | Val Loss: 0.141171\n","Epoch: 12/20 | Step: 2300 | Train Loss: 0.104328 | Val Loss: 0.144740\n","Epoch: 13/20 | Step: 2400 | Train Loss: 0.028383 | Val Loss: 0.150120\n","Epoch: 14/20 | Step: 2500 | Train Loss: 0.048150 | Val Loss: 0.158377\n","Epoch: 14/20 | Step: 2600 | Train Loss: 0.000710 | Val Loss: 0.168125\n","Epoch: 15/20 | Step: 2700 | Train Loss: 0.037298 | Val Loss: 0.165091\n","Epoch: 15/20 | Step: 2800 | Train Loss: 0.029409 | Val Loss: 0.174988\n","Epoch: 16/20 | Step: 2900 | Train Loss: 0.051040 | Val Loss: 0.185396\n","Epoch: 16/20 | Step: 3000 | Train Loss: 0.005645 | Val Loss: 0.208587\n","Epoch: 17/20 | Step: 3100 | Train Loss: 0.112262 | Val Loss: 0.225756\n","Epoch: 17/20 | Step: 3200 | Train Loss: 0.007773 | Val Loss: 0.241375\n","Epoch: 18/20 | Step: 3300 | Train Loss: 0.041734 | Val Loss: 0.199873\n","Epoch: 18/20 | Step: 3400 | Train Loss: 0.000160 | Val Loss: 0.202096\n","Epoch: 19/20 | Step: 3500 | Train Loss: 0.011557 | Val Loss: 0.251364\n","Epoch: 19/20 | Step: 3600 | Train Loss: 0.034603 | Val Loss: 0.229705\n","Epoch: 20/20 | Step: 3700 | Train Loss: 0.003808 | Val Loss: 0.230625\n","Epoch: 20/20 | Step: 3800 | Train Loss: 0.022683 | Val Loss: 0.254915\n"]}]},{"cell_type":"code","source":["# Get test data loss and accuracy\n","\n","test_losses = []\n","num_correct = 0\n","total = 0\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","net.eval()\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()\n","\n","        # Initialize hidden state for each batch\n","        h = net.init_hidden(inputs.size(0))\n","        h = tuple(each.detach() for each in h)\n","\n","        # Forward pass\n","        output, h = net(inputs, h)\n","\n","        # Compute loss\n","        test_loss = criterion(output, labels)\n","        test_losses.append(test_loss.item())\n","\n","        # Get predicted class (0,1,2)\n","        preds = torch.argmax(output, dim=1)\n","\n","        # Count correct predictions\n","        num_correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","# --- Final Stats ---\n","\n","print(\"Test Loss: {:.3f}\".format(np.mean(test_losses)))\n","\n","test_acc = num_correct / total\n","print(\"Test Accuracy: {:.3f}\".format(test_acc))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qhjnwUru9Ldo","outputId":"e06c1d57-110d-4dc8-fc6b-f93fcd775403","executionInfo":{"status":"ok","timestamp":1771232949293,"user_tz":-360,"elapsed":387,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.318\n","Test Accuracy: 0.931\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","\n","def preprocess_text(text, vocab_to_int, seq_length):\n","\n","    text = text.lower()\n","    words = text.split()\n","\n","    ints = []\n","    for word in words:\n","        if word in vocab_to_int:\n","            ints.append(vocab_to_int[word])\n","        else:\n","            ints.append(0)\n","\n","    features = np.zeros(seq_length, dtype=int)\n","\n","    if len(ints) <= seq_length:\n","        features[-len(ints):] = ints\n","    else:\n","        features[:] = ints[:seq_length]\n","\n","    return features\n"],"metadata":{"id":"4hepf7rJtkZy","executionInfo":{"status":"ok","timestamp":1771233108765,"user_tz":-360,"elapsed":52,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def predict(net, text, vocab_to_int, seq_length=200):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    net.to(device)\n","    net.eval()\n","\n","    features = preprocess_text(text, vocab_to_int, seq_length)\n","\n","    inputs = torch.from_numpy(features).unsqueeze(0).to(device)\n","\n","    h = net.init_hidden(1)\n","    h = tuple(each.detach() for each in h)\n","\n","    with torch.no_grad():\n","        output, h = net(inputs, h)\n","        probs = F.softmax(output, dim=1)\n","        pred_class = torch.argmax(probs, dim=1).item()\n","\n","    return pred_class, probs.cpu().numpy()\n"],"metadata":{"id":"-GSgc8YUuI82","executionInfo":{"status":"ok","timestamp":1771233123397,"user_tz":-360,"elapsed":9,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["label_map = {\n","    0: \"Negative\",\n","    1: \"Neutral\",\n","    2: \"Positive\"\n","}\n","text = \"কিবোর্ড নিয়ে আমি ভীষন হতাশ\"\n","\n","pred_class, probabilities = predict(net, text, vocab_to_int)\n","\n","print(\"Predicted Class:\", pred_class)\n","print(\"Sentiment:\", label_map[pred_class])\n","print(\"Probabilities:\", probabilities)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afDhbf11uMzS","executionInfo":{"status":"ok","timestamp":1771233730052,"user_tz":-360,"elapsed":24,"user":{"displayName":"PRAGGA BARUA","userId":"11633258946467898144"}},"outputId":"eb553688-9361-4c90-a20c-61c1c58db603"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Class: 0\n","Sentiment: Negative\n","Probabilities: [[0.4337275  0.15023589 0.4160366 ]]\n"]}]}]}